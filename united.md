# 딥러닝이란?
## 1) 딥러닝의 정의
사람의 신경망을 모방하여 만든 인공신경망을 통해 기계가 다층구조로 학습하도록 하는 기술
## 2) 인공지능, 머신러닝, 딥러닝의 개념
![image](https://user-images.githubusercontent.com/109254140/183793142-eda45d36-040a-4934-a9a3-c3d6acd73f54.png)

* 인공지능 : 사람의 지능을 모방하여 복잡한 일을 할수 있는 기계
* 머신러닝 : 과거 데이터를 분석하여 새로운 데이터에 대한 예측 기대 결정을 스스로 내리도록 하는 방법
* 딥러닝 : 인간의 뉴런과 비슷한 인공신경망 알고리즘을 사용한 방식으로 정보를 처리하는 방법

## 3) 인공신경망이란?
인공신경망(ANN, artificial neural network) : 신경망을 사람들이 인공적으로 만든것
![image](https://user-images.githubusercontent.com/109254140/183793224-aef99dfb-1ad3-4a7f-a4e4-b42d33c1f53e.png)

인공신경망에는 신경망의 최소 구성 단위인 뉴런이 다른 뉴런과 연결된 모습을 각각의 층 
즉 레이어라는 개념을 사용하여 연결하고 있다
* Input Layer(입력층) : 데이터를 입력하는층    
* Hidden Layer(은닉층) : 입력층에서 들어온 데이터가 여러 신호로 바뀌어서 출력층까지 전달시켜줌 <br>
                         이때 연결된 여러 뉴런을 지날때마다 신호세기가 변경된다
* Output Layer(출력층) : 출력층에 어떤값을 전달함에 따라 인공지능의 예측값이 결정된다

### 생물학적 뉴런과 인공신경망 뉴런의 유사점
![image](https://user-images.githubusercontent.com/109254140/183793243-8de300bf-ae5d-4b75-abf8-44ccc06a376c.png)

* 생물학적인 신경 세포 뉴런을 수학적으로 모델링한것이 인공신경망 뉴런이다. 
* 생물학적 뉴런이 다른 여러개의 뉴런으로부터 입력값을 받아서 세포체에 저장하다가 자신의 용량을 넘서 외부로 출력값을 내보내는것 처럼, 인공신경망 뉴런 역시 여러 입력값을 받아 일정수준이 넘어서면 활성화 되어 출력값을 보낸다 

## 4) 가중치(Weight)와 편향(Bias)  
![image](https://user-images.githubusercontent.com/109254140/183793295-c9f90887-5314-4fa5-baad-5f9d89cda951.png)

### 가중치란?   
각 입력 신호가 결과 출력에 미치는 중요도를 조절하는 매개변수  
각 뉴런과 뉴런을 연결하는 선에 존재

* 신호를 전달받는 뉴런은 하나의 뉴런에서만 신호를 전달받는것이 아니라 여러 뉴런에서 신호를 전달받으면 인공 신경망도 이와 비슷하다  
* 이때 단순하게 신호를 전달해주는것이 아니라 신호 세기를 변경해서 전달한다

### 편향이란?   
뉴런의 활성화 조건을 설정하는 매개변수  
각 층에 하나의 값으로 존재

![image](https://user-images.githubusercontent.com/109254140/183793324-7b8b38fc-10b6-46f9-8a21-4892c711fd1d.png)

 * 뒤쪽으로 전달되는 신호 세기는   
앞쪽 뉴런에서 전달한 신호값에 가중치값을 곱하고  
편향값을 더해서 다음으로 전달한다

 * 가중치와 편향은 신호의세기를 변경하는데 사용한다    
즉 다음 뉴런으로 전달되는 신호의 세기는 가중치와 편향에 의해 결정된다.
가중치가 어떤값인가에 따라 학습이 잘된 건지 아닌지 구분된다

-> 인공신경망이 학습한다는건 가중치와 편향값을 데이터에 맞게끔 정교하게 맞추어간다는것이다.

## 5) 활성화 함수 (Activation function)
![image](https://user-images.githubusercontent.com/109254140/183793357-449efa90-8c03-4c6b-b309-151e2e0d4f54.png)

여러 뉴런에서 들어온 신호 세기를 특정한 값으로 바꾸기 위해 사용하는 함수가 활성화 함수이다.  
활성화 함수는 신호 세기를 조절하는데, 레이어와 레이어 사이에 있어서 여러뉴런에서 특정 뉴런으로 가는 신호를 종합해서 하나의 값으로 바꿔주는 역할을 한다.

### 종류
* 이진 활성화 함수 (Binary step activation function)
* 선형 활성화 함수 (Linear activation function)
* 비선형 활성화 함수 (Non-linear activation function)

#### 활성화 함수로 비선형 함수를 이용해야하는 이유
* 신호 전달 체계가 선형이 아니기 때문이다. 
  - 활성화 함수로 선형 함수를 쓰면 신경망의 층을 깊게하는 의미가 없어지기 때문이다
### 비선형 활성화 함수의 종류  
#### 시그모이드 함수 (Sigmoid function)
![image](https://user-images.githubusercontent.com/109254140/183793372-edf2e2ac-b1e5-4a18-b2f4-d17ef5d6b999.png)

#### 하이퍼볼릭탄젠트 함수 (Hyperbolic tangent function)
![image](https://user-images.githubusercontent.com/109254140/183793387-de84574d-067a-4b42-8b1b-8394047014a8.png)

#### ReLU 함수 (Rectified Linear Unit function)
![image](https://user-images.githubusercontent.com/109254140/183793405-304b0311-0ad4-4227-a275-f2b31d9d7cd9.png)

#### 리키 렐루함수(Leaky ReLU)
![image](https://user-images.githubusercontent.com/109254140/183793422-3e09e8c6-042f-4da0-8870-3ed68d629dd5.png)

#### 소프트맥스 함수 (Softmax function)
![image](https://user-images.githubusercontent.com/109254140/183793464-35843bc7-8e76-40f1-90ef-ccfd75f8da98.png)

## 6) 딥러닝의 작동 순서
 1. 데이터를 입력합니다.
 2. 여러 층을 통해 예상 결과값을 만듭니다.
 3. 실제 값과 비교해서 그 차이를 구합니다. 
 4. 차이를 줄이기 위한 방법으로 앞의 층들의 가중치를 수정해줍니다. 
 5. 이 방법의 반복으로 규칙을 계속 개선합니다.

## 7) 딥러닝의 구분

### 1. 인공신경망 (Artificial Neural Network, ANN)
![image](https://user-images.githubusercontent.com/109254140/183793475-f4cb8454-6f8a-49ef-8f65-a5d863ecf564.png)

### 2. 심층 신경망(Deep Neural Network, DNN)
![image](https://user-images.githubusercontent.com/109254140/183793486-97f5d570-72ce-469d-8b10-017cfcd00a27.png)


 * 심층 신경망과 일반적인 신경망의 핵심적인 차이점는 층의 개수(깊이)입니다.

### 3. 합성곱 신경망(Convolutional Neural Network, CNN) 
![image](https://user-images.githubusercontent.com/109254140/183793500-f733ad80-69b9-45a1-8783-8bc783afe9e9.png)

* 이미지 공간 정보를 유지한체로 학습이 가능한 모델
* 시각세포의 작동 원리를 본떠서 만들고 이미지를 특정한 영역별로 추출하여 학습시킨다.
* 이미지 및 비디오 인식, 추천 시스템, 이미지 분료, 의료 이미지 분석 및 자연어 처리에 응용된다.
* 이미지를 하나의 데이터가 아닌, 여러 개로 분할하여 처리 할수있다.
* 이미지가 왜곡되더라도 이미지의 부분적 특성을 추출가능하다.

### 4.  순환 신경망(Recurrent Neural Network, RNN) 
![image](https://user-images.githubusercontent.com/109254140/183793525-a1e47561-94e1-4599-a961-d9ae6690fc4e.png)

* 하나의 신경망을 계속적으로 반복해서 학습하는 것을 의미한다.  
* 연속데이터에 대한 결과를 예측하거나 분류할때 사용된다.
* 필기 인식이나 음성 인식같은 데이터를 처리하는데 적용할 수 있다.

## 8) 딥러닝의 장단점
### 장점
1. 수천 개의 작업을 사람보다 더 빠르게 반복해서 수행할 수 있습니다
2. 원시 데이터에서 수동으로 기능을 추출할 필요가 없으므로 시간을 절약할 수 있습니다.
3. 딥 러닝에 사용되는 신경망에는 다양한 데이터 형식과 애플리케이션에 적용할 수 있는 기능을 가짐 
4. 딥 러닝 모델은 새로운 데이터로 재학습하여 적용할 수 있습니다

### 단점
1. 데이터 학습 자체에 오랜 시간이 필요
2. 많은 양의 데이터와 질 높은 데이터가 필요
3. 딥러닝의 대부분이 블랙박스이므로 신경망이 어떻게 결정을 내리는지 설명 및 이해하기가 어렵다

## 9) 딥러닝의 활용용도
1. 소셜 미디어  
딥 러닝은 많은 수의 이미지를 분석하는 데 사용될 수 있으며, 이를 통해 소셜 네트워크는 사용자에 대한 정보를 더 많이 찾아낼 수 있습니다. 이는 대상 광고를 개선하고 제안을 따릅니다.

2. 재무  
딥 러닝의 신경망은 주식 가치를 예측하고 거래 전략을 개발하는 데 사용될 수 있으며 보안 위협을 감지하고 사기로부터 보호할 수도 있습니다.

3. 헬스케어  
딥 러닝은 추세와 행동을 분석하여 환자의 질병을 예측함으로써 보건의료 분야에서 중추적인 역할을 수행할 수 있습니다. 또한 보건의료 종사자는 딥 러닝 알고리즘을 활용하여 환자에 대한 최적의 검사 및 치료를 결정할 수 있습니다.

4. 사이버 보안  
딥 러닝은 알려진 위협 데이터베이스에 대응하는 대신 의심스러운 새 활동을 인식하여 기존 맬웨어 솔루션보다 고급 위협을 더 효과적으로 감지할 수 있습니다.

# 2.  AI의 역사
![image](https://user-images.githubusercontent.com/109254140/183793551-08848a7a-662e-4ace-8b88-330f86cb1b70.png)

## 1) 1차 AI붐(1956~1974) 

* 다트머스 회의에서 존 매카시 교수가 다트머스 회의에서 인공지능 개념을 정의 인공지능 용어를 처음 사용 (1956)
* 신경망을 인공적인 소프트웨어 아키텍쳐로 구성한 뒤, 가중치에 따라 유연하게 동작이 변화한다는 개념의 퍼셉트론의 등장(1958)
  -  기호적 AI는 두뇌구조와는 다르지만 컴퓨터 작동 방식으로 충분히 구현할수 있다는 논리에 초점을 맞춤
  - 간단한 대수학문제를 풀고 수학정리를 증명하고 언어를 학습하기도 함
  - 사람들은 완전한 지능을 가진 기계가 나올거라 낙관(인공지능 낙관론)
* 마빈 민스키(Marvin Minsky)교수의 XOR 같은 복잡한 문제를 해결할수 없다 주장 (1969)  

## 2) 첫번째 겨울의 시대(1974~1980)
* 모라벡의 역설 "인간에게 쉬운것이 AI에겐 어렵다"
  - 인간에게는 당연한 낮은기술의 걷기 듣기 보기 등을 하는데 AI는 엄청난 양의 리소스가 필요하여 이를 구현하는건 매우 어렵다
* 상식의 저주  "인간에겐 상식 수준의 지식들도 AI는 모두 배워야만 가능하다"
  - 상식 수준의 지식들도 AI는 모두 배워야만 가능하다는 것으로 인간에게는 손과 발이 2개씩 있다 같은 우리에겐 너무나 당연한 지식이 AI에게는 어려운 문제로 작용한다는 것이다


* 기계는 한정된 상황 문제해결만 가능 변수가 많은 현실에서는 무력 -> 투자급감

## 3) 2차 AI붐(1980~1987) 
* 다층 퍼셉트론(1980), 역전파(1986) 로 XOR 문제 해결
* 특정영역의 지식을 입력하고 추론을 하게 한 결과 기계가 전문가 수준으로 판단할수 있는 전문가 시스템의 등장 모라벡의 역설과 상식에 저주를 전문가 시스템으로 돌파
* 전문가 시스템 (Expert System) : 인간이 특정분야에 대하여 가지고 있는 전문적인 지식을 정리하고 표현하여 컴퓨터에 기억시킴으로써, 일반인도 이 전문지식을 이용할 수 있도록 하는 시스템이다

## 4) 두 번째 겨울의 시대(1987~1993)
* Vanishing gradient 문제(1986) : 다층 퍼셉트론이 되면서부터 층이 길어지고, sigmoid의 특성 상 층이 길어지면 점차 그 계산 값이 희미해지는 특성이 문제로 대두
* AI는 인간이 넣어준 지식 이외에는 결코 답변도 연결도 할수 없음
* 프레임 문제 - AI는 모든것을 다 고려해서 한없이 생각할수 밖에 없다
 - 인공지능은 제한된 범위에서만 정보를 처리하므로 실제 발생하는 문제를 처리할 수 없다

## 5) 3차 AI붐(1993~ 현재)
* 인공지능망을 구해낸 제프리 힌튼(2006) - ReLU 활성화 함수 제안
  - 인공신경망이 길어질수록 값이 희미해져서 문제가 되었던 sigmoid 대신 ReLU 활성화 함수를 사용해서 Vanishing gradient 문제를 해결.
* 대량의 데이터로부터 지식을 얻는 머신러닝의 실용화
* 전문가 시스템이 지식을 데이터로 저장하는것이라면 머신러닝은 데이터로부터 새로운 지식을 꺼내 학습
* 이미지 인식 대회에서 제프리 힌튼이 주도한 토론토대학의 슈퍼비전이 압도적 승리 (2012)
* 마이크로소프트는 무려 백신 2개 층을 가진 딥러닝 구조로 3.56%의 에러율에 도달 (2015)
* 알파고(2016)

### 딥러닝이 부상한 이유
1. 하드웨어의 발전으로 연산에 소요되는 시간 단축됨 -> 기술의발전
2. 빅데이터 다량의 자료와 정보들을 분석되어 학습에 이용가능 -> 인터넷의 폭팔적 성장
3. 학습이란 데이터를 특징에 따라 분류하는것이고 특징들은 인간이 입력할 수밖에 없고 이것이 기계학습에 최대 난제 인간이 뇌에서 무의식적으로 하는 특징을 가르치는데 문제가생김
(Featur Design 문제 - 우리의 뇌가 작동하는 방법을 잘 모르기 때문에 컴퓨터에게 제대로 가르칠 수 없음)  이것을 해결한것이 딥러닝

* 딥러닝은 데이터를 바탕으로 컴퓨터가 스스로 특징을 만든다 특징 자체를 학습하는 진정한 의미의 학습이라고 할 수 있다.

* 머신러닝은 특징들을 인간이 입력해 주지만, 딥러닝의 경우 AI가 데이터로부터 적절한 특징들을 스스로 찾아낸다.

# 통계기반 머신러닝이란?
 * 통계학적으로 대규모 데이터에 내재된 패턴을 찾아내는 학습 모델
 * 통계를 통해 문제 해결하는 방법
   - 데이터를 나누는 분류(classification)
   - 데이터로 앞으로 필요한 결과를 예측(Prediction) 
   
-> 통계 기반 머신러닝은 이 분류와 예측을 프로그램화한 것으로 분류와 예측을 주어진 데이터를 자동으로 계산해 특징량 (feature)을 추출합니다.




# 2. 회귀 (regression)란?

<br>

![img121.png](https://raw.githubusercontent.com/lsc3976/P_deeplearning1/main/image/121.png)



회귀분석(regression analysis)은 영국 학자 프랜시스 골턴(Francis Galton)에 의해 <br>
'평균으로의 회귀'(regression to the mean)현상을 증명하기위해 처음 고안되었다.  <br>
'평균으로의 회귀'는 부모와 아이 키의 상관관계를 분석할때 부모의 키가 아주 크더라도 <br>
자식의 키가 부모보다 더 커서 세대를 이어가면서 무한정 커지는(발산) 것은 아니며, <br>
부모의 키가 아주 작더라도 자식의 키가 부모보다 더 작아서 세대를 이어가며 무한정 작아지는(수렴)것이 아니라는 것. <br>
즉, 극단적인 값이 오더라도, 다음 측정값은 평균으로 회귀하는 경향성을 일반화하기위해 쓴 용어이다. <br>
현대에서는 회귀(regress), 즉 평균으로 돌아간다는 의미는 거의 사라지고, <br>
독립변수와 종속변수를 설정하고 이들의 관계를 통계적으로 살펴보는 방법론들을 회귀분석이라고 한다. <br>

<br>

## 회귀분석의 정의

<br>

``` 
"원인에 대한 결과를 수치로 예측하는 기법" 
```
<br>
회귀분석은 주어진 자료들이 어떤 특정한 경향성을 띠고 있다는 아이디어로부터 비롯된다. <br>
주어진 변수들 사이에서 나타나는 경향성을 설명하는 것을 주 목적으로 하기 때문에, <br>
변수들 사이의 함수적인 관련성을 규명하기 위해 어떤 수학적 모형(회귀식)을 가정하고 <br>
이 회귀식을 측정된 변수들의 자료로부터 추정하는 통계적 분석 방법이다.<br><br>

<img src='http://drive.google.com/uc?export=view&id=13RLGQKAu6Pa2oeaEXyGpXkwLvTZFXpyR' /><br>

이때 영향을 주는 원인을 독립변수라 하고 영향받아나온 결과를 종속변수라고한다. <br><br>

따라서 독립변수들의 패턴을 찾아 관련성을 회귀식으로 추정해내고 <br>
나아가 새로운 변수를 주었을때의 결과까지 수치로 예측하는것을 회귀분석이라고 할수있다.<br>

$Y = W_1 X_1 + W_2 X_2 + W_3 X_3 + ... + W_n X_n $

위와같은 선형회귀식을 예로들면 Y는 종속변수(결과값). <br>
$X_1,X_2,X_3, ... X_n$은 독립변수(원인). <br>
$W_1,W_2,W_3, ... W_n$은 독립변수의 값에 영향을 주는 회귀 계수(Regression coefficients)이다. <br>
머신 러닝의 관점에서보면 독립변수는 피처, 종속변수는 결정 값이다. <br>
머신 러닝 회귀 예측의 핵심은 주어진 피처와 결정값 데이터 기반 학습을 통해 __최적의 회귀계수__ 를 찾아내는것이다. <br><br>



## 회귀분석의 종류

회귀분석의 종류는는 회귀 계수의 선형/비선형 여부, 독립변수의 개수, 종속변수의 개수에 따라 여러가지 유형으로 나눌 수 있다. <br>
회귀에서 가장 중요한 것은 회귀 계수이며, 이 회귀 계수가 선형인지 아닌지에 따라 선형 회귀와 비선형 회귀로 나눌 수 있다. <br>
그리고 독립변수의 개수가 한 개인지 여러 개인지에 따라 단일 회귀, 다중 회귀로 나뉜다. <br><br>


### 단순 회귀분석 (Simple Regression Analysis)

![ima122.png](https://github.com/lsc3976/P_deeplearning1/blob/main/image/122.png?raw=true)<br>
종속변수에 영향을 미치는 독립변수가 1개이면 단순 회귀분석이라고한다.<br>
(ex : 독립변수를 근무년수로, 월급을 종속변수로 설정하여 인과관계를 분석)<br><br>

### 다중 회귀분석 (Multiple Regression Analysis)

![ima122.png](https://github.com/lsc3976/P_deeplearning1/blob/main/image/123.png?raw=true)<br>
2개 이상의 독립변수를 통해 종속변수에 미치는 인과관계를 분석한다.<br>
(ex : 독립변수를 나이, 근무년수, 이직횟수 등으로 다양화 하여 종속변수인 월급을 분석)<br><br>

각 독립변수들이 실제로 종속변수에 영향을 미친다면 다중 회귀분석이 더욱 정확한 결과값을 예측할수있다.<br><br>


### 선형 회귀
일반적으로 가장 많이 사용되는 회귀로써 실제 값과 예측값의 차이(오류의 제곱 값)를 최소화하는 직선형 회귀선을 최적화하는 방식이다.<br>
선형 회귀 모델은 규제(Regularization)방법에 따라 다시 별도의 유형으로 나뉠 수 있다.<br>
규제는 일반적인 선형 회귀의 과적합 문제를 해결하기 위해서 회귀 계수에 패널티 값을 적용하는 것을 말한다.<br><br>


### 비선형 회귀
비선형 회귀란 독립변수와 종속변수간의 관계에 대해 회귀 계수가 비선형적인 모델을 찾는 방법이다.<br>
기존의 선형 회귀와 달리 임의의 관계로 모델을 추정하는것이 비선형 회귀법이다. 반복 추정 알고리즘을 사용하여 수행된다.<br><br>




# 3. Linear Regression (선형 회귀)

 
<br><br>

## 선형 회귀(Linear Regression)란?

머신 러닝의 가장 큰 목적은 실제 데이터를 바탕으로 모델을 생성하고 <br>
다른 특정 입력 값을 넣었을때 발생할 아웃풋을 예측하는데에 있다. <br>
선형 회귀(Linear Regression)는 직관적이고 데이터의 경향성을 가장 잘 설명하는 하나의 직선을 예측하는 지도학습 기법이다. <br>
독립변수와 종속변수 데이터를 주고 모델을 트레이닝시켜서 정확도를 높이고, <br>
주어진 독립변수 X에 해당하는 실제 값으로 타겟 Y(종속변수)를 예측할때 이 회귀식의 계수(입력 피처)들이 선형조합으로 표현된다. <br>


<br><BR>

## 선형 회귀의 정의
  
  
  
  
  ### 1) 단순 선형 회귀
  

  
  

  <img src='https://github.com/lsc3976/P_deeplearning1/blob/main/image/10.png?raw=true' /><br>
  (일반적인 단순 선형회귀)
  <br><br>
  
  예를 들어 집의 크기(독립 변수)를 사용해서 주택 가격(종속 변수)을 예측할때
  
  $Y$(price) $= w_0 + w_1 * X$(size)
  
  라는 1차 함수식(회귀식)으로 모델링 할수있다.
  이때 기울기 $w_1$과 절편인 $w_0$을 회귀 계수(Regression coefficients)로 지칭한다. <br>
  위와 같은 1차 함수로 모델링했다면 실제 주택 가격은 이러한 1차 함수 값에서 실제 값만큼의 오류 값을 빼거나 더한 값이 된다.
  
  이렇게 실제값과 회귀 모델의 차이에 따른 오류값을 남은 오류, 즉 잔차(residual)라 부른다. <br>
  __최적의 회귀 모델을 만든다는 것__ 은 전체 데이터의 잔차(오류값)합이 최소가 되는 모델을 만든다는 의미이며, <br>
  동시에 오류값 합이 최소가 될 수 있는 __최적의 회귀 계수를 찾는다__ 는 의미이다.
  <br>
  
  <img src="https://github.com/lsc3976/P_deeplearning1/blob/main/image/55525.png?raw=true" /> <br>
  일반적인 기울기를 구하는 최소제곱법의 해<br><br>
  
  
  
  
  ### 2) 다중 선형 회귀

  사실 주택 가격은 단순히 집의 크기(하나의 독립변수)만으로 결정되지않고 <br>
  방의 개수, 주변 교통수단과의 거리 등 다양한 요소로부터 영향을 받는다. <br>
  

  $Y = w_1X_1 + w_2X_2 + w_3X_3 +  ...  + w_nX_n + b$

  이러한 다수의 독립 변수를 가지고 주택 가격을 예측할때 Y(종속변수)는 여전히 1개 이지만 <br>
  X(독립변수)는 여러개가 된다. 이것을 다중 선형 회귀 분석이라고 한다.
  <br><br><br>
  
  
## 손실 함수

<br>
<img src='/image/117.png' /><br>
 
```
손실 함수 : 실제 y 값에 비해 가정한 모델 h(x))(추정값)이 얼마나 잘 예측했는지 판단하는 함수이다.
```

회귀식을 모델링 할 경우 당연히 실제 데이터와 회귀식에는 오차가 발생 한다. <br>
선형회귀는 위에 언급된 오류값(잔차)의 합이 최소가 되는 최적 회귀 계수를 찾는 것 <br>
(가장 정확한 예측선을 긋는 것)이 궁극적인 목표가 된다.<br>

* 어떠한 문제를 해결하고자 하는가에 따라 적합한 손실함수를 설정해야 좋은 결과를 얻을 수 있다. <br>

 ### 비용 함수
 
 머신러닝 알고리즘에서 최적화는 비용함수의 값이 가장 작아지는 최적의 파라미터를 찾는 과정을 말한다. <br>
 이를 달성하기 위해서, 경사하강법(Gradient Descent) 기반의 방식이 가장 기본이 되는 알고리즘이다. <br>

 목적함수란, 최적화 알고리즘에서 최대값 또는 최소값을 찾아야하는 함수를 말한다. <br>
 즉, 비용함수는 최적화 알고리즘의 목적함수이다. <br>

 
회귀 모델에 쓰이는 비용함수에는 MSE, MAE, RMES 등이 있으며 <br>
분류 모델에 쓰이는 비용함수에는 Binary cross-entropy, Categorical cross-entropy 등이 있다. 
<br><br>
 
 <img src="/image/116.png"> <br>
평균 제곱 오차 (Mean Squre Error, MSE)의 경우<br>
n은 총 데이터, y는 출력결과이고 t는 실제 데이터의 값이다. <br>
출력결과 - 실제데이터의 차이 를 제곱(음수가 나오는걸 방지)한뒤 평균을 내어 표현하고있다. <br>
이와같이 비용함수는 손실함수를 사용하여 정의될 수 있다. <br>

  
따라서 선형회귀란 임의의 직선을 그어 회귀식 계수를 추정하고 오차값을 계산하여 <br>
그것을 0에 가깝게 만들어주는 a와 b라는 회귀계수를 찾아가는 작업이다. 
 
<br><br><br>


  
## 비선형 회귀(Non-linear Regression)란?
  

  <br>
<img src='https://github.com/lsc3976/P_deeplearning1/blob/main/image/12.png?raw=true' /><br>

비선형 모델은 입력되는 데이터(독립 변수, 종속 변수)를 어떻게 변형 하더라도 <br>
회귀 계수를 선형 결합식으로 표현할 수 없는 모델을 말한다. <br>
  
선형 회귀 모델은 파라미터(회귀 계수)에 대한 해석이 단순하지만 <br>
비선형 회귀 모델은 모델의 형태가 복잡할 경우 해석이 매우 어려워진다. <br>
그래서 보통 모델의 해석을 중시하는 통계 모델링에서는 비선형 회귀 모델을 잘 사용하지 않는다. <br>
하지만 회귀 모델의 목적이 해석이 아니라 결과값의 예측에 있다면 비선형 모델은 대단히 유연하기 때문에 <br>
복잡한 패턴을 갖는 데이터에 대해서도 모델링이 가능하고 충분히 많은 데이터를 갖고 있어서 오류값을 줄일수있고 <br>
예측 자체가 목적인 경우에 비선형모델은 매우 뛰어난 도구가 된다.
  
<br><br><br>
 

## 활성화 함수
  
  <br>
  
  
  
### 뉴런에서 해답 가져오기
  
  
  <img src='https://github.com/lsc3976/P_deeplearning1/blob/main/image/133.png?raw=true' /><br>
  인간은 컴퓨터와 달리 목소리, 사진, 언어 와 같은 Unstructrued Data를 쉽게 이해하고 활용 가능하다. <br>
  그것은 뇌의 뉴런, 수상돌기로부터 특정 정보 $x_n$를 받아들이고 시텝틱 가중치 $w_i$를 적용하는 일련의 과정을 거치기때문이다.<br>
  이 가중치는 입력에 얼마나 반응해야하는지를 정의한다. ( $x_n$ $w_i$를 통해 활성화)<br>
  이 모든 값들은 뉴런 핵에서  $y=\sum_i x_i wi+b$ 로 통합되고 일정 수준을 넘어서면 활성화되어 해당 정보를 축삭(axon)으로 보내져서<br>
  다른 프로세스를 거치는데, 일반적으로 σ(y)를 통해서 비선형처리가 된다. 이 후 최종 목적지를 거쳐 다른 뉴런으로 보내진다. <br>
  이처럼, 인간의 뇌가 작동하는 방식을 모방해 비선형 회귀 모델을 구축하면 놀랍게도 컴퓨터가 마치 인간처럼<br>
  구조화되지않은 자료(보이스,사진,언어)를 이해하고 활용할수 있게된다. 이것이 비선형 회귀의 강력한 핵심이다.
<br><br><br>
  
  

  ### 활성화 함수의 정의


  <img src='/image/1110.png' /><br>
  뉴런처럼 입력 신호의 총합을 출력 신호로 변환하는 함수를 일반적으로 활성화 함수라고 한다. <br>
  입력 신호의 총합이 활성화를 일으키는지를 정하는 역할이다.<br>
  위 그림은 신경망 그림으로 가중치(w)와 피처(x)의 곱연산과 편향(b)의 총합을 계산하고<br>
  그 다음에 함수 f에 넣어 출력하는 흐름을 보여준다.<br>
 
  <br><br>
 
  <br>
  
  ### 1) 시그모이드(Sigmoid) 함수

  <br><br>
  <img src='https://github.com/lsc3976/P_deeplearning1/blob/main/image/778.png?raw=true' /><br>
  
  $sigmoid(x) = \frac{1}{1 +e^-x}$ <br>
  
  시그모이드 함수는 Logistic 함수라고 불리기도 하며, <br>
  x의 값에 따라 0~1의 값을 출력하는 S자형 함수이다. <br>
 

 
 
  
 
  <br>
  



  ### 2) ReLU (Rectified Linear Unit) 함수
<br>
  <img src='https://github.com/lsc3976/P_deeplearning1/blob/main/image/783.png?raw=true' /><br>
  레이어의 층이 깊어질수록 내부 은닉층(hidden layer)을 활성화 시키는 함수로 <br>
  ReLU라는 활성화 함수를 사용하게 되는데, 이 함수는 쉽게 말해 0보다 작은 값이 나온 경우 0을 반환하고, <br>
  0보다 큰 값이 나온 경우 그 값을 그대로 반환하는 함수다. 0보다 큰 값일 경우 1을 반환하는 시그모이드와 다르다. <br>
  <br>

  시그모이드와 ReLU 이외에도 여러가지 활성화 함수가 있다. <br><br>

  
